{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alouwyck/dania-international-days/blob/main/deep_learning/Intro_to_Deep_Learning_demo_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DyJxjGGXV07j"
      },
      "source": [
        "<img src=\"data:image/png;base64,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\" align=\"right\" /><br>\n",
        "\n",
        "**Dania International Days**<br>\n",
        "13 - 15 March 2024<br><br>\n",
        "Workshop by Andy Louwyck\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-KkWI-G73CE"
      },
      "source": [
        "# **INTRODUCTION TO DEEP LEARNING WITH PYTHON**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovKTLLil8f4N"
      },
      "source": [
        "## **Simple Linear Regression**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset"
      ],
      "metadata": {
        "id": "UkAhK1FEudsv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd  # python data analysis library\n",
        "\n",
        "df = pd.read_excel('age_couple.xlsx')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "nIMDVFRin1tz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe().T  # T transposes the table"
      ],
      "metadata": {
        "id": "0ABwCvDCVhQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt  # python library for visualizations\n",
        "\n",
        "df.plot.scatter(x=\"Husband's age\", y=\"Wife's age\");\n",
        "plt.grid();"
      ],
      "metadata": {
        "id": "fMeiTaFgVmiP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# independent and dependent variable\n",
        "\n",
        "X = df[[df.columns[1]]]   # husband's age\n",
        "y = df[[df.columns[-1]]]  # wife's age"
      ],
      "metadata": {
        "id": "CAmmh3Hboh7p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use Scikit-Learn to apply OLS"
      ],
      "metadata": {
        "id": "ty_4RswjuWZj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "exact = LinearRegression()\n",
        "exact.fit(X, y)\n",
        "m, b = exact.coef_[0][0], exact.intercept_[0]\n",
        "m, b"
      ],
      "metadata": {
        "id": "E-Q2pjZufZHB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "yp = exact.predict(X)\n",
        "print(\"MSE is\", mean_squared_error(y_true=y, y_pred=yp))\n",
        "print(\"MAE is\", mean_absolute_error(y_true=y, y_pred=yp))\n",
        "print(\"R² is\", r2_score(y_true=y, y_pred=yp))"
      ],
      "metadata": {
        "id": "7yaTSR4-mpza"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use Keras to apply SGD"
      ],
      "metadata": {
        "id": "8XyquV6Aug2B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras  # keras is tensorflow's high-level API!\n",
        "\n",
        "model = keras.Sequential()  # instantiate Sequential\n",
        "model.add(keras.layers.Dense(units=1))  # add 1 layer with 1 unit or node"
      ],
      "metadata": {
        "id": "QwEy2J-JoQv9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=\"mse\",       # MSE\n",
        "              optimizer=\"sgd\")  # Stochastic Gradient Descent"
      ],
      "metadata": {
        "id": "xUqR3pWHoYuO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = model.fit(X, y,\n",
        "                   epochs=15);  # number of times the algorithm processes the training set"
      ],
      "metadata": {
        "id": "xeGX3Zy0og1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to normalize X!"
      ],
      "metadata": {
        "id": "bpCqcUIOu36T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# feature scaling!\n",
        "Xn = X / 100\n",
        "yn = y / 100"
      ],
      "metadata": {
        "id": "PnDndhIppRzp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Dense(1))\n",
        "model.compile(optimizer=\"rmsprop\",  # a variant of SGD that is more robust\n",
        "              loss=\"mse\")\n",
        "result = model.fit(Xn, yn,\n",
        "                   epochs=5000,  # we need a lot of epochs to reach the minimum\n",
        "                   verbose=0);   # suppress output"
      ],
      "metadata": {
        "id": "OY_9rYg8pZcF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(result.history['loss']);\n",
        "plt.grid();\n",
        "plt.xlabel('epoch');\n",
        "plt.ylabel('MSE');"
      ],
      "metadata": {
        "id": "Ea-iC4KNp2-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m2, b2 = tuple(model.layers[0].weights)\n",
        "m2 = m2.numpy().squeeze().item()\n",
        "b2 = b2.numpy().squeeze().item()\n",
        "m2, b2  # different result because of feature scaling"
      ],
      "metadata": {
        "id": "ROWVHS-lqQ07"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yp = model.predict(Xn) * 100  # multiply by 100 to undo the scaling!"
      ],
      "metadata": {
        "id": "1QxJsUtOrKcv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"MSE is\", mean_squared_error(y_true=y, y_pred=yp))\n",
        "print(\"MAE is\", mean_absolute_error(y_true=y, y_pred=yp))\n",
        "print(\"R² is\", r2_score(y_true=y, y_pred=yp))"
      ],
      "metadata": {
        "id": "PSPjxSYmokgz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np  # numeric python\n",
        "\n",
        "# scatter plot\n",
        "df.plot.scatter(x=df.columns[1], y=df.columns[-1]);\n",
        "plt.grid();\n",
        "\n",
        "# exact regression line\n",
        "xline = np.array([0, 100])\n",
        "yline = m * xline + b  # y = mx + b\n",
        "plt.plot(xline, yline, 'r-', label='exact');\n",
        "\n",
        "# approximate regression line\n",
        "xline = np.array([0, 1])\n",
        "yline = m2 * xline + b2\n",
        "plt.plot(xline * 100, yline * 100, 'k:', label='approximate');  # don't forget to scale back!\n",
        "plt.legend();"
      ],
      "metadata": {
        "id": "V9Xri6kwqrSm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Logistic Regression**"
      ],
      "metadata": {
        "id": "VjAdZDDzmAHB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The sigmoid function"
      ],
      "metadata": {
        "id": "dQ350yHPuo2S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "x = np.linspace(-10, 10, 100)  # create array of 100 evenly spaced points between -10 and 10\n",
        "sigmoid = lambda x: 1 / (1 + np.exp(-x))\n",
        "\n",
        "plt.plot(x, sigmoid(x), 'k-');\n",
        "plt.grid();\n",
        "plt.title('sigmoid function');\n",
        "plt.xlabel('x');\n",
        "plt.ylabel('y');"
      ],
      "metadata": {
        "id": "TRINaQZzIOne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset"
      ],
      "metadata": {
        "id": "gzEDWslburO3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('Student_Passed.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "CGuzoleAJaJ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe().T"
      ],
      "metadata": {
        "id": "pACRV2L_J7JF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.passed.sum()  #  balanced dataset!"
      ],
      "metadata": {
        "id": "fEk-OWqZKFR3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "def students_scatterplot(df):\n",
        "    _, ax = plt.subplots(1, 1)\n",
        "    df[df.passed==1].plot.scatter(x=\"time_study\", y=\"number_courses\", color=\"green\", ax=ax);\n",
        "    df[df.passed==0].plot.scatter(x=\"time_study\", y=\"number_courses\", color=\"red\", ax=ax);\n",
        "    plt.grid();\n",
        "    return ax\n",
        "\n",
        "students_scatterplot(df);"
      ],
      "metadata": {
        "id": "62dxHb7lKQYM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# feature and labels\n",
        "\n",
        "X = df[['time_study', 'number_courses']].values  # features\n",
        "y = df['passed'].values  # labels"
      ],
      "metadata": {
        "id": "0KPSZfklnFRu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use Scikit-Learn"
      ],
      "metadata": {
        "id": "ug52n3miuwZx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "reg = LogisticRegression(penalty=None)\n",
        "reg.fit(X, y)\n",
        "reg.score(X, y)  # accuracy"
      ],
      "metadata": {
        "id": "pOZNdAAXnadA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "students_scatterplot(df)\n",
        "xline = np.array([0, 8])\n",
        "yline = -(reg.intercept_.item() + reg.coef_[0][0] * xline) / reg.coef_[0][1]\n",
        "xl, yl = plt.xlim(), plt.ylim()\n",
        "plt.plot(xline, yline, 'b-');\n",
        "plt.xlim(xl);\n",
        "plt.ylim(yl);"
      ],
      "metadata": {
        "id": "Th_nT2KCOa94"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use Keras"
      ],
      "metadata": {
        "id": "x_t_V5AKuzYR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Xn = X / 8             # feature scaling! divide all features by the maximum value of 8\n",
        "yn = y.reshape(-1, 1)  # reshape 1D vector y so it becomes a 2D column vector"
      ],
      "metadata": {
        "id": "nK3wf0QeMHWw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Dense(units=1,  # one node only\n",
        "                             activation='sigmoid'))  # sigmoid as activation function"
      ],
      "metadata": {
        "id": "-FIguABQLmLM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "-VbXXA8FL6iL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = model.fit(Xn, yn,\n",
        "                   epochs=1000,\n",
        "                   batch_size=64,\n",
        "                   verbose=0)  # no output"
      ],
      "metadata": {
        "id": "AqlwNfT-MG4U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_loss_accuracy(result):\n",
        "    fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True)\n",
        "    ax1.plot(result.history['loss']);\n",
        "    ax1.grid();\n",
        "    ax1.set_ylabel('Log Loss');\n",
        "    ax2.plot(result.history['accuracy']);\n",
        "    ax2.grid();\n",
        "    ax2.set_ylabel('Accuracy');\n",
        "    ax2.set_xlabel('Epochs');\n",
        "    return ax1, ax2\n",
        "\n",
        "plot_loss_accuracy(result);"
      ],
      "metadata": {
        "id": "5Ch6KkefM5S4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc = tuple(model.evaluate(Xn, yn))\n",
        "print('Log Loss:', loss)\n",
        "print('Accuracy:', acc)"
      ],
      "metadata": {
        "id": "5MCJET01NIQN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set learning rate to a higher value!"
      ],
      "metadata": {
        "id": "GnSZ5qOWvByd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Dense(units=1, activation='sigmoid'))\n",
        "optimizer = keras.optimizers.RMSprop(learning_rate=0.1)  # by default, the learning rate is 0.001\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=optimizer,\n",
        "              metrics=['accuracy'])\n",
        "result = model.fit(Xn, yn, epochs=1000, batch_size=64, verbose=0)"
      ],
      "metadata": {
        "id": "JeBE0GFT-PVj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_loss_accuracy(result);"
      ],
      "metadata": {
        "id": "IbvIodDg-ye9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc = tuple(model.evaluate(Xn, yn))\n",
        "print('Log Loss:', loss)\n",
        "print('Accuracy:', acc)"
      ],
      "metadata": {
        "id": "WI0J6wWz-7eW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Predicting House Prices**"
      ],
      "metadata": {
        "id": "URunfUPpc_dA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset"
      ],
      "metadata": {
        "id": "0L5W0gBmvGek"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import boston_housing  # Boston housing dataset\n",
        "\n",
        "(train_data, train_labels), (test_data, test_labels) = boston_housing.load_data()"
      ],
      "metadata": {
        "id": "Lap_qeCvxXXb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data.shape)  # 404 samples, 13 features\n",
        "print(test_data.shape)  # 102 samples, 13 features"
      ],
      "metadata": {
        "id": "CMNCGr_Nxe5E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True)\n",
        "ax1.hist(train_labels);\n",
        "ax1.set_ylabel('training set');\n",
        "ax2.hist(test_labels);\n",
        "ax2.set_xlabel('median house price (1000$)');\n",
        "ax2.set_ylabel('test set');"
      ],
      "metadata": {
        "id": "PDfNGWUmxu5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalizing the data!"
      ],
      "metadata": {
        "id": "vmUW0QKWvIpW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mean = train_data.mean(axis=0)  # mean\n",
        "std = train_data.std(axis=0)  # standard deviation\n",
        "train_data -= mean\n",
        "train_data /= std\n",
        "test_data -= mean\n",
        "test_data /= std"
      ],
      "metadata": {
        "id": "lYkx13E-xsyt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The ReLU activation function"
      ],
      "metadata": {
        "id": "J29SD1xrvMBD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ReLU as activation function\n",
        "import numpy as np\n",
        "\n",
        "relu = lambda x: np.maximum(x, 0)\n",
        "\n",
        "x = np.linspace(-10, 10, 100)\n",
        "plt.plot(x, relu(x), 'k-');\n",
        "plt.title('ReLU function');\n",
        "plt.xlabel('x');\n",
        "plt.ylabel('y');\n",
        "plt.grid();"
      ],
      "metadata": {
        "id": "pM0ca_nkDDlz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The neural network"
      ],
      "metadata": {
        "id": "6CohYV3GvPng"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(32, activation=\"relu\"),\n",
        "    keras.layers.Dense(32, activation=\"relu\"),\n",
        "    keras.layers.Dense(1)  # regression so no activation in output layer\n",
        "])\n",
        "\n",
        "model.compile(optimizer=\"rmsprop\", loss=\"mse\", metrics=[\"mae\"])"
      ],
      "metadata": {
        "id": "BxUk0M0Tyie-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = model.fit(\n",
        "    train_data, train_labels,\n",
        "    epochs=500,\n",
        "    batch_size=16,\n",
        "    validation_split=0.1,  # keep 10% of training data for validation!\n",
        "    verbose=0\n",
        "  )"
      ],
      "metadata": {
        "id": "i6mljmA0ywb8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.semilogy(result.history['loss'], label='training');\n",
        "plt.semilogy(result.history['val_loss'], label='validation');\n",
        "plt.legend();\n",
        "plt.grid();\n",
        "plt.xlabel('epoch');\n",
        "plt.ylabel('MSE');"
      ],
      "metadata": {
        "id": "ZFZZm4_kzafT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Avoid overfitting!"
      ],
      "metadata": {
        "id": "HgHZbkgxvTSr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# build\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(32, activation=\"relu\"),\n",
        "    keras.layers.Dense(32, activation=\"relu\"),\n",
        "    keras.layers.Dense(1)  # regression so no activation in output layer\n",
        "])\n",
        "\n",
        "# compile\n",
        "model.compile(optimizer=\"rmsprop\", loss=\"mse\", metrics=[\"mae\"])\n",
        "\n",
        "# train\n",
        "result = model.fit(\n",
        "    train_data, train_labels,\n",
        "    epochs=300,\n",
        "    batch_size=16,\n",
        "    verbose=0\n",
        "  )"
      ],
      "metadata": {
        "id": "hILrkpG3z6wF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluating the model"
      ],
      "metadata": {
        "id": "MVNp6D0HvXye"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mse, mae = tuple(model.evaluate(train_data, train_labels, verbose=0))\n",
        "print('TRAINING SET')\n",
        "print(\"  MSE =\", mse)\n",
        "print(\"  MAE =\", mae)\n",
        "\n",
        "mse, mae = tuple(model.evaluate(test_data, test_labels, verbose=0))\n",
        "print('TEST SET')\n",
        "print(\"  MSE =\", mse)\n",
        "print(\"  MAE =\", mae)"
      ],
      "metadata": {
        "id": "yysReIeGz_7I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "\n",
        "yp_train = model.predict(train_data, verbose=0)\n",
        "print('Training R² is', r2_score(y_true=train_labels, y_pred=yp_train))\n",
        "\n",
        "yp_test = model.predict(test_data, verbose=0)\n",
        "print('Test R² is', r2_score(y_true=test_labels, y_pred=yp_test))"
      ],
      "metadata": {
        "id": "uYVXcbDqMKyq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Text Classification**"
      ],
      "metadata": {
        "id": "chqUZsUo7egT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is vectorization?"
      ],
      "metadata": {
        "id": "rjx-bdmAvbWl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "docs = ['The cat sat on the mat.',\n",
        "        'When the cat is away, the mice will play!']\n",
        "docs"
      ],
      "metadata": {
        "id": "lyR0bNLMWVM9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# standarization\n",
        "\n",
        "import re  # module for regular expressions\n",
        "\n",
        "docs = [doc.lower() for doc in docs]  # lower case\n",
        "docs = [re.sub(r'[^\\w\\s]', '', doc) for doc in docs]  # remove punctuations\n",
        "docs"
      ],
      "metadata": {
        "id": "96zrZ-_oW_TB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenization\n",
        "docs = [doc.split(\" \") for doc in docs]\n",
        "docs"
      ],
      "metadata": {
        "id": "sB81Ind03KhC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vocabulary {word: index}\n",
        "\n",
        "unique_words = set([word for doc in docs for word in doc])\n",
        "vocabulary = {word: id for id, word in enumerate(unique_words)}\n",
        "vocabulary"
      ],
      "metadata": {
        "id": "3lpiqkpRX7An"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# text to integer vectors\n",
        "samples = [[vocabulary[word] for word in doc] for doc in docs]\n",
        "samples"
      ],
      "metadata": {
        "id": "BPC0SQk-Ydz7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# multi-hot encoding\n",
        "import numpy as np\n",
        "\n",
        "X = np.zeros((len(samples), len(vocabulary)), dtype=int)\n",
        "for i, sample in enumerate(samples):\n",
        "    X[i, sample] = 1\n",
        "X"
      ],
      "metadata": {
        "id": "Wudqw3soY4IV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "pd.DataFrame(columns=vocabulary.keys(), data=X)"
      ],
      "metadata": {
        "id": "778rFQIp5JG1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZNU5CAYB-Ns"
      },
      "source": [
        "The dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4Q4lA4qApAu"
      },
      "source": [
        "from keras.datasets import imdb  # the IMDB dataset\n",
        "\n",
        "num_words = 10_000  # restrict to the 10 000 most frequent words\n",
        "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=num_words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data.shape)\n",
        "print(test_data.shape)"
      ],
      "metadata": {
        "id": "mmRH8uvtq8fS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihFFLdh7D91z"
      },
      "source": [
        "# labels are 1 (=positive) or 0 (=negative)\n",
        "\n",
        "train_labels[0]  # label of the first review"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnW1U6lhDFYM"
      },
      "source": [
        "# the data have already been vectorized\n",
        "\n",
        "train_data[0][:10]  # the first 10 words from the first review"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fexiAp2XEPm8"
      },
      "source": [
        "# the vocabulary is limited to 10 000 words\n",
        "\n",
        "print(max([max(review) for review in train_data]))\n",
        "print(max([max(review) for review in test_data]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5A7xIEVkEgAZ"
      },
      "source": [
        "# get the words\n",
        "word_index = imdb.get_word_index()  # dict {word=index}\n",
        "reverse_word_index = {index: value for value, index in word_index.items()} # we want dict {index=word}\n",
        "\" \".join([reverse_word_index[i] for i in train_data[0][:50]])  # first 50 words of first sample"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZAIVGezFFBJ"
      },
      "source": [
        "# apply multi-hot encoding\n",
        "\n",
        "def multi_hot(data):\n",
        "    x = np.zeros((len(data), num_words))\n",
        "    for i, review in enumerate(data):\n",
        "        x[i, review] = 1.\n",
        "    return x\n",
        "\n",
        "x_train = multi_hot(train_data)\n",
        "x_test = multi_hot(test_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X40K8kR5JiX3"
      },
      "source": [
        "# convert labels to single precision floats\n",
        "y_train = np.asarray(train_labels).astype(\"float32\")\n",
        "y_test = np.asarray(test_labels).astype(\"float32\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The neural net"
      ],
      "metadata": {
        "id": "gon1pUAGviz8"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SX9-o-3K8zK"
      },
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(16, activation='relu'),\n",
        "    keras.layers.Dense(16, activation='relu'),\n",
        "    keras.layers.Dense(1, activation='sigmoid'),\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_7GR4vqO0cP"
      },
      "source": [
        "model.compile(\n",
        "    optimizer=\"rmsprop\",\n",
        "    loss=\"binary_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The validation set"
      ],
      "metadata": {
        "id": "5FDw2MJEvlGd"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26w1waXtRiFg"
      },
      "source": [
        "# create validation set\n",
        "\n",
        "n = 10_000\n",
        "x_val = x_train[:n]\n",
        "partial_x_train = x_train[n:]\n",
        "y_val = y_train[:n]\n",
        "partial_y_train = y_train[n:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PL1gM3dbTBCf"
      },
      "source": [
        "result = model.fit(\n",
        "    partial_x_train,\n",
        "    partial_y_train,\n",
        "    epochs=15,\n",
        "    batch_size=512,\n",
        "    validation_data=(x_val, y_val)  # validation set\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDgzrfyjTrgD"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True)\n",
        "\n",
        "epochs = range(1, len(result.history['loss']) + 1)\n",
        "ax1.plot(epochs, result.history['loss'], \"b-\", label=\"Training\");\n",
        "ax1.plot(epochs, result.history['val_loss'], \"r-\", label=\"Validation\");\n",
        "ax1.set_ylabel('Loss');\n",
        "ax1.grid();\n",
        "\n",
        "ax2.plot(epochs, result.history['accuracy'], \"b-\", label=\"Training\");\n",
        "ax2.plot(epochs, result.history['val_accuracy'], \"r-\", label=\"Validation\");\n",
        "ax2.set_xlabel('Epochs');\n",
        "ax2.set_ylabel('Accuracy');\n",
        "ax2.grid();\n",
        "ax2.legend();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Avoid overfitting!"
      ],
      "metadata": {
        "id": "PKr7Lf2Hvn7O"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQPxPw0-UChW"
      },
      "source": [
        "# build\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(16, activation='relu'),\n",
        "    keras.layers.Dense(16, activation='relu'),\n",
        "    keras.layers.Dense(1, activation='sigmoid'),\n",
        "])\n",
        "\n",
        "# compile\n",
        "model.compile(\n",
        "    optimizer=\"rmsprop\",\n",
        "    loss=\"binary_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "# fit\n",
        "result = model.fit(\n",
        "    x_train,   # full training set!\n",
        "    y_train,\n",
        "    epochs=4,  # 4 instead of 20!!\n",
        "    batch_size=512,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluating the model"
      ],
      "metadata": {
        "id": "jY1iCkv7vqTS"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eaYeZT9WMJi"
      },
      "source": [
        "# evaluate model\n",
        "loss, acc = tuple(model.evaluate(x_test, y_test))\n",
        "print('Log Loss:', loss)\n",
        "print('Accuracy:', acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the model predicts probabilities!\n",
        "\n",
        "prob = model.predict(x_test, verbose=0)\n",
        "prob"
      ],
      "metadata": {
        "id": "JMISo9veEd4d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# use round() to convert probabilities into labels!\n",
        "yp = np.round(prob)\n",
        "yp"
      ],
      "metadata": {
        "id": "Znop5HI1ErpT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "ConfusionMatrixDisplay.from_predictions(y_true=y_test, y_pred=yp,\n",
        "                                        normalize='all',\n",
        "                                        display_labels=('neg', 'pos'),  # labels for 0 and 1\n",
        "                                        colorbar=False);  # no colorbar"
      ],
      "metadata": {
        "id": "epvCMVFZEtqF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLelnAcFLGio"
      },
      "source": [
        "## **Image Classification**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset"
      ],
      "metadata": {
        "id": "DNYQ4PHyvtRg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wS7CyBWSoBOw"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import mnist  # the MNIST dataset\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RHcKrqEd6o0T"
      },
      "outputs": [],
      "source": [
        "print(f\"The training set constains {len(train_images)} images\")\n",
        "print(f\"The test set contains {len(test_images)} images\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MWP2VkwgrbeN"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "digit = train_images[4]  # 5th image (index 4!)\n",
        "plt.imshow(digit, cmap=plt.cm.binary)  # plot image\n",
        "plt.title(f\"Label: {train_labels[4]}\");  # label for 5th image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(digit)"
      ],
      "metadata": {
        "id": "VqKvTOJhugx1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "digit.shape"
      ],
      "metadata": {
        "id": "e-LKFw26u25S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "digit.dtype"
      ],
      "metadata": {
        "id": "W_A03fr-vKw-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "digit.min(), digit.max()"
      ],
      "metadata": {
        "id": "BlCIF_OGvNSD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kaKDkXL7pho1"
      },
      "outputs": [],
      "source": [
        "train_images = train_images.reshape((60000, 28 * 28))  # reshape\n",
        "train_images = train_images.astype(\"float32\") / 255  # normalize and convert to float\n",
        "test_images = test_images.reshape((10000, 28 * 28))  # reshape\n",
        "test_images = test_images.astype(\"float32\") / 255  # normalize and convert to float"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our own hand-written digit"
      ],
      "metadata": {
        "id": "L2C5FfsnvwQO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EmOSq0Vfsc66"
      },
      "outputs": [],
      "source": [
        "# own hand written digit\n",
        "import PIL\n",
        "digit = PIL.Image.open(\"digit.png\")  # read image\n",
        "digit = digit.resize((28, 28))  # resize image to 28 x 28\n",
        "digit = digit.convert('L')  # convert image to black and white (L = luminance)\n",
        "digit = np.array(digit)  # convert image to numpy array\n",
        "digit = 255 - digit  # turn black into whihte and white in to black\n",
        "digit = digit.astype(\"float32\") / 255.0  # normalize array\n",
        "plt.imshow(digit, cmap=plt.cm.binary);  # plot digit"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A fully connected network"
      ],
      "metadata": {
        "id": "hBXeDzVXvzNC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NweLXwZEoaNc"
      },
      "outputs": [],
      "source": [
        "# a fully connected neural net\n",
        "\n",
        "from tensorflow import keras\n",
        "\n",
        "model = keras.Sequential([\n",
        " keras.layers.Dense(512, activation=\"relu\"),  # hidden layer consisting of 512 neurons and relu as activation\n",
        " keras.layers.Dense(10, activation=\"softmax\")  # output layer consisting of 10 neurons and softmax as activation\n",
        "])\n",
        "\n",
        "model.build(input_shape=(None, 28 * 28))  # number of neurons for the input layer\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s7NPPa3HogsY"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    loss=\"sparse_categorical_crossentropy\",  # loss function that calculates difference between predicted and true labels\n",
        "    optimizer=\"rmsprop\",  # algorithm that minimizes the loss function\n",
        "    metrics=[\"accuracy\"]  # calculate accuracy after each iteration (epoch)\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1hlWFNtIpCkg"
      },
      "outputs": [],
      "source": [
        "model.fit(train_images, train_labels, epochs=5, batch_size=128);  # training the model using the training set"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluating the model"
      ],
      "metadata": {
        "id": "Bf6HfNxNv5Lk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H8nXhGl2qZDG"
      },
      "outputs": [],
      "source": [
        "test_loss, test_acc = model.evaluate(test_images, test_labels)  # evaluate model using the test set\n",
        "print(f\"accuracy on the test set: {test_acc}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our own digit"
      ],
      "metadata": {
        "id": "zRVBSKKtv6jV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8h-k0ix2liAy"
      },
      "outputs": [],
      "source": [
        "probs = model.predict(digit.reshape(1, -1))  # predict returns 10 probabilities\n",
        "probs[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PhWd3s38cCwX"
      },
      "outputs": [],
      "source": [
        "prob = np.max(probs) * 100  # largest probability\n",
        "n = np.argmax(probs)  # index (= digit) corresponding to the largest probability\n",
        "print(f\"The neural network is for {prob:.2f} % sure the digit is {n}!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convolutional network"
      ],
      "metadata": {
        "id": "RTUYl9lKv8xN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iM7pPbffvZoQ"
      },
      "outputs": [],
      "source": [
        "# convolutional neural net\n",
        "\n",
        "model = keras.Sequential([\n",
        "  keras.layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\"),\n",
        "  keras.layers.MaxPooling2D(pool_size=2),\n",
        "  keras.layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\"),\n",
        "  keras.layers.MaxPooling2D(pool_size=2),\n",
        "  keras.layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\"),\n",
        "  keras.layers.Flatten(),\n",
        "  keras.layers.Dense(10, activation=\"softmax\")  # output layer consisting of 10 neurons and softmax as activation\n",
        "])\n",
        "\n",
        "model.build(input_shape=(None, 28, 28, 1))  # input consists of images of 28 x 28 pixels en 1 color channel\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "45oPdwOWwfE3"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    loss=\"sparse_categorical_crossentropy\",  # loss function\n",
        "    optimizer=\"rmsprop\",  # optimizer\n",
        "    metrics=[\"accuracy\"]  # accuracy as metric\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hJQlNa8zwN4m"
      },
      "outputs": [],
      "source": [
        "# a convnet processes images!\n",
        "\n",
        "train_images = train_images.reshape((60000, 28, 28, 1))\n",
        "test_images = test_images.reshape((10000, 28, 28, 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FjB9t04mL_GV"
      },
      "outputs": [],
      "source": [
        "model.fit(train_images, train_labels, epochs=5, batch_size=64);"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluating the model"
      ],
      "metadata": {
        "id": "APO-cJaXwBIo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SXdsVuHkME5d"
      },
      "outputs": [],
      "source": [
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(f\"accuracy on the test set: {test_acc}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our own digit"
      ],
      "metadata": {
        "id": "gDoQSSuuwDlT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WDIyvqFrsi3G"
      },
      "outputs": [],
      "source": [
        "probs = model.predict(digit[np.newaxis, :, :])  # add extra dimension!\n",
        "prob = np.max(probs) * 100\n",
        "n = np.argmax(probs)\n",
        "print(f\"The convnet is for {prob:.2f} % sure that the digit is {n}!\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}